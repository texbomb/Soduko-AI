{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Import and prepare initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sudokus to load\n",
    "load_number = 1000\n",
    "\n",
    "\n",
    "quizzes = np.zeros((load_number+1, 81), np.int32)\n",
    "solutions = np.zeros((load_number+1, 81), np.int32)\n",
    "for i, line in enumerate(open('sudoku.csv', 'r').read().splitlines()[1:]):\n",
    "    quiz, solution = line.split(\",\")\n",
    "    for j, q_s in enumerate(zip(quiz, solution)):\n",
    "        q, s = q_s\n",
    "        quizzes[i, j] = q\n",
    "        solutions[i, j] = s\n",
    "    if i == load_number:\n",
    "        break\n",
    "quizzes = quizzes.reshape((-1, 9, 9))\n",
    "solutions = solutions.reshape((-1, 9, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "dataset['quizzes'] = quizzes\n",
    "dataset['solutions'] = solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SudokuDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, sudoku_list, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.sudoku_list = sudoku_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sudoku_list['quizzes'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        quiz = self.sudoku_list['quizzes'][idx]\n",
    "        solution = self.sudoku_list['solutions'][idx]\n",
    "        sample = {'quizzes': quiz, 'solutions': solution}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SudokuDataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=  batch_size,\n",
    "        shuffle=  True,\n",
    "        drop_last=False)\n",
    "\n",
    "train_iterator = train_loader.__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([2, 9, 9])"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "batch['quizzes'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "         \n",
    "        # self.placement_net = nn.Sequential(\n",
    "        #     nn.Linear( 81, 81),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Linear( 81, 81),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Linear( 81, 81),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Linear( 81, 9)\n",
    "        #     nn.Softmax(dim=1)\n",
    "        # )\n",
    "        \n",
    "        self.number_net = nn.Sequential(\n",
    "            nn.Linear( 82, 81),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear( 81, 81),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear( 81, 81),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear( 81, 9),\n",
    "            #nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        quiz = batch['quizzes'] # Dim B x 9 x 9\n",
    "        B = quiz.shape[0]\n",
    "        quiz = quiz.reshape(B, 81) # Dim B x 81\n",
    "\n",
    "        prediction = torch.zeros(B,81,9)\n",
    "\n",
    "        for i in range(81):\n",
    "            placement = torch.ones(B,1) * i\n",
    "            net_input = torch.cat( (quiz, placement.int()) , dim=1)\n",
    "            prediction[:,i,:] = self.number_net( net_input.float() )\n",
    "\n",
    "\n",
    "        #placement_values , placement_guess = torch.max(placement_prob, 1)\n",
    "        #placement =  placement_values.reshape(-1,1)       \n",
    "        #number_prob = self.number_net( torch.cat((quiz , placement.int()), dim=1 ).float() )\n",
    "        #number_values , number_guess = torch.max(number_prob, 1)\n",
    "        \n",
    "        return prediction  #  placement_values, placement_guess, placement_prob, number_values, number_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.forward(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(2.2323, grad_fn=<NllLossBackward>)\ntensor(2.2845, grad_fn=<NllLossBackward>)\ntensor(2.2188, grad_fn=<NllLossBackward>)\ntensor(2.2042, grad_fn=<NllLossBackward>)\ntensor(2.2024, grad_fn=<NllLossBackward>)\ntensor(2.2002, grad_fn=<NllLossBackward>)\ntensor(2.1992, grad_fn=<NllLossBackward>)\ntensor(2.1978, grad_fn=<NllLossBackward>)\ntensor(2.1980, grad_fn=<NllLossBackward>)\ntensor(2.1979, grad_fn=<NllLossBackward>)\ntensor(2.1978, grad_fn=<NllLossBackward>)\ntensor(2.1980, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1976, grad_fn=<NllLossBackward>)\ntensor(2.1977, grad_fn=<NllLossBackward>)\ntensor(2.1977, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1975, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1980, grad_fn=<NllLossBackward>)\ntensor(2.1975, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1975, grad_fn=<NllLossBackward>)\ntensor(2.1978, grad_fn=<NllLossBackward>)\ntensor(2.1977, grad_fn=<NllLossBackward>)\ntensor(2.1976, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1987, grad_fn=<NllLossBackward>)\ntensor(2.1976, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1975, grad_fn=<NllLossBackward>)\ntensor(2.1975, grad_fn=<NllLossBackward>)\ntensor(2.1975, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1975, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1975, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1976, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1971, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1978, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1979, grad_fn=<NllLossBackward>)\ntensor(2.1983, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1975, grad_fn=<NllLossBackward>)\ntensor(2.1980, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1976, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1978, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1975, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1976, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1975, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1975, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1974, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1973, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\ntensor(2.1972, grad_fn=<NllLossBackward>)\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-189-edd0206f8a88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mprediction\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'solutions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-182-513eccf9c043>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mplacement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mnet_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mquiz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mprediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_net\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnet_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Bachelor\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Bachelor\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Bachelor\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Bachelor\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Bachelor\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1369\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    batch = train_iterator.next()\n",
    "    prediction  = model.forward(batch)\n",
    "    prediction = prediction.reshape(-1,9)\n",
    "    loss = loss_function(prediction, batch['solutions'].reshape(-1).long()-1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    torch.save(model.state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(prediction, solution):\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    loss = loss_func(prediction, solution)\n",
    "    \n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitf0cf2fac8bd64d0ea267e12187f5daaa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}